# -*- coding: utf-8 -*-
"""Custom Training YOLOv5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D6t8J7V90C3MxDxrOy7LPMcJif-ElRZx

<a align="left" href="https://ultralytics.com/yolov5" target="_blank">
<img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/splash_horizontal.png"></a>

This is the **official YOLOv5 ðŸš€ notebook** authored by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). 
For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!

# Setup

Clone repo, install dependencies and check PyTorch and GPU.
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
# %pip install -qr requirements.txt  # install dependencies

import torch
from IPython.display import Image, clear_output  # to display images

clear_output()
print(f"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})")

!unzip -q ../train_data.zip -d ../

"""# 1. Inference

`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:

<img src="https://user-images.githubusercontent.com/26833433/114307955-5c7e4e80-9ae2-11eb-9f50-a90e39bee53f.png" width="900">

## Inferencing for Large Yolo
"""

!python detect.py --weights runs/train/exp6/weights/best.pt --img 640 --conf 0.5 --source ../Final.mp4

"""## Inferencing for small Yolo"""

!python detect.py --weights runs/train/exp7/weights/best.pt --img 640 --conf 0.5 --source ../Final.mp4

"""# 2. Train

Download [COCO128](https://www.kaggle.com/ultralytics/coco128), a small 128-image tutorial dataset, start tensorboard and train YOLOv5s from a pretrained checkpoint for 3 epochs (note actual training is typically much longer, around **300-1000 epochs**, depending on your dataset).
"""

# Download COCO128
torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')
!unzip -q tmp.zip -d ../ && rm tmp.zip

"""Train a YOLOv5s model on [COCO128](https://www.kaggle.com/ultralytics/coco128) with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and **COCO, COCO128, and VOC datasets are downloaded automatically** on first use.

All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.

"""

# Commented out IPython magic to ensure Python compatibility.
# Tensorboard  (optional)
# %load_ext tensorboard
# %tensorboard --logdir runs/train

# Commented out IPython magic to ensure Python compatibility.
# Weights & Biases  (optional)
# %pip install -q wandb
import wandb
wandb.login()

"""## Train YOLOv5 small model on Custom Data for 3000 epochs"""

# Train YOLOv5 small model on Custom Data for 3000 epochs
!python train.py --img 640 --batch 8 --epochs 3000 --data custom_data.yaml --weights yolov5s.pt --cache

"""## Train YOLOv5 Medium on Custom Data for 1500 epochs"""

!python train.py --img 640 --batch 8 --epochs 1500 --data custom_data.yaml --weights yolov5m.pt --cache

"""## Train YOLOv5 Large on Custom Data for 500 epochs"""

# Train YOLOv5 Large on Custom Data for 500 epochs
!python train.py --img 640 --batch 8 --epochs 500 --data custom_data.yaml --weights yolov5l.pt --cache

"""# 3. Visualize

## Local Logging

All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and test jpgs to see mosaics, labels, predictions and augmentation effects. Note a **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934).

## For Large Yolo
"""

Image(filename='runs/train/exp6/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels
Image(filename='runs/train/exp6/test_batch0_labels.jpg', width=800)  # test batch 0 labels
Image(filename='runs/train/exp6/test_batch0_pred.jpg', width=800)  # test batch 0 predictions

"""## For Medium Yolo"""

Image(filename='runs/train/exp8/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels
Image(filename='runs/train/exp8/test_batch0_labels.jpg', width=800)  # test batch 0 labels
Image(filename='runs/train/exp8/test_batch0_pred.jpg', width=800)  # test batch 0 predictions

"""Training losses and performance metrics are also logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and a custom `results.txt` logfile which is plotted as `results.png` (below) after training completes. Here we show YOLOv5s trained on COCO128 to 300 epochs, starting from scratch (blue), and from pretrained `--weights yolov5s.pt` (orange).

## For Small Yolo
"""

Image(filename='runs/train/exp2/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels
Image(filename='runs/train/exp2/test_batch0_labels.jpg', width=800)  # test batch 0 labels
Image(filename='runs/train/exp2/test_batch0_pred.jpg', width=800)  # test batch 0 predictions

"""## For Large Yolo"""

from utils.plots import plot_results 
plot_results(save_dir='runs/train/exp6')  # plot all results*.txt as results.png
Image(filename='runs/train/exp6/results.png', width=800)

"""## For Small Yolo"""

from utils.plots import plot_results 
plot_results(save_dir='runs/train/exp2')  # plot all results*.txt as results.png
Image(filename='runs/train/exp2/results.png', width=800)

"""## For Medium Yolo"""

from utils.plots import plot_results 
plot_results(save_dir='runs/train/exp8')  # plot all results*.txt as results.png
Image(filename='runs/train/exp8/results.png', width=800)

"""# Environments

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):

- **Google Colab and Kaggle** notebooks with free GPU: <a href="https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> <a href="https://www.kaggle.com/ultralytics/yolov5"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a>
- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)
- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)
- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href="https://hub.docker.com/r/ultralytics/yolov5"><img src="https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker" alt="Docker Pulls"></a>

# Status

![CI CPU testing](https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg)

If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([test.py](https://github.com/ultralytics/yolov5/blob/master/test.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/models/export.py)) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.
"""